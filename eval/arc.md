# 构建金融对话数据集方案

我想构建金融领域对话数据集，对话内容涉及股票、基金等领域的分析，投资咨询等，并且根据需要测试LLM,agent的一些指标

## 1) 调研的现有数据集

### 1.1 最接近“多轮金融对话”的公开数据：ConvFinQA（但偏“财报数值推理”，不是“投资咨询”）

* **ConvFinQA** 是明确的金融领域**多轮对话**数据集（3,892 段对话，14,115 问题），要求模型在多轮中保持上下文并做数值推理，基于财报表格+文本。(https://huggingface.co/datasets/FinGPT/fingpt-convfinqa)
* 但它的核心任务是 **document-grounded QA / 数值推理链**，更像“分析师围绕财报问答”，不包含你要测的关键项：**用户画像（风险等级/期限/禁忌）**、**风险提示模板触发**、**合规边界（避免交易指令/收益承诺）**这些“投顾对话”的结构化标签。

ConvFinQA 数据集是基于数值的金融分析，可以测试Agent的金融数值分析能力

---

### 1.2 “金融对话/咨询语料”方向：FinTalk-19k、DISC-Fin-SFT 等（但多为“短对话/指令数据”）

* **FinTalk-19k**：来自公开 Reddit 讨论的“金融话题对话条目”（带 instruction/response/context/tag），更偏“个人理财讨论/问答”，不保证长多轮结构，也没有你的画像/风险提示标注。(https://huggingface.co/datasets/ceadar-ie/FinTalk-19k) 
    * 主要是偏日常的金融、经济类问答，可以测试Agent的个性化辅助决策能力
* **DISC-FinLLM / DISC-Fin-SFT**：中文金融指令微调数据集（约 24.6 万条），包含“金融咨询指令”等子集，但通常是**指令-回答**形式，不天然是长多轮；也不一定提供你要的细粒度指标真值（画像、风险提示覆盖等）。(https://github.com/FudanDISC/DISC-FinLLM?tab=readme-ov-file)
  * 包含专业金融知识的问答，可以测试Agent专业知识检索、网络检索能力

✅ 结论：这类数据可以当作**语言风格/问法覆盖**的来源，但要满足你第六章的指标，仍然需要你自己构造“带真值标签的多轮数据”。

---

### 1.3 “投资咨询长对话”公开开源：基本缺位

我在检索里能找到一些“付费/合成”的投资咨询对话集（例如明确写“由 ChatGPT 生成的 financial guidance conversations”）。([Grandma's Boy Labs][4])
但这类不是学术常用基准，且可复现/质量/标注一致性都不一定满足论文要求。

✅ 结论：**如果你要严格匹配 6.1(A,B) + 6.2(1-5) 的评测闭环，LLM 合成几乎是主路径。**公开数据更多是“参考与种子”，不是终点。

---

## 2) 为了满足 6.2 的评价指标（1-5），数据集应该“长什么样”？

你 6.2 的 1-5（对话连续性、画像准确、风险提示、合规率、解释度）要能量化，关键是：**数据必须自带“可核验的真值（ground truth）”**，而不是只存对话文本。

下面给你一套**可直接落地的“数据结构 + 生成流程 + 标注规则 + 质量控制”**方案，覆盖 6.1 的 A（模拟多轮）和 B（半真实交互）。

---

## 3) 数据集总体设计：A（模拟）+ B（半真实）

### 3.1 统一的数据 Schema（建议 JSONL）

每条样本是一段多轮对话（6–12 轮为主），字段建议：

**(1) 对话元信息**

* `dialog_id`
* `scenario_type`：行情解读 / 产品比较 / 风险识别 / 投资教育 / 合规对抗
* `difficulty`：easy/med/hard（hard 多用“主题漂移→回收、跨轮约束冲突”）
* `language`：zh/en

**(2) 用户画像真值（用于指标2）**

* `profile_gt`：

  * `risk_level_gt`：保守/稳健/进取
  * `horizon_gt`：≤6月 / 6-24月 / 2年以上
  * `liquidity_need_gt`：高/中/低
  * `constraints_gt`：禁忌与约束（如“不做短线/不碰港股/最大回撤<15%”）
  * `preferences_gt`：偏好（如“指数/红利/新能源/低波动”）

**(3) 多轮对话本体（用于指标1、3、4、5）**

* `turns[]` 每轮含：

  * `role`: user/assistant
  * `text`
  * `turn_tags`（仅对 assistant 轮强制）：

    * `memory_required_keys_gt`：该轮回答应该引用哪些历史关键信息（用于上下文关联度/一致性）
    * `risk_disclosure_required_gt`：需要哪些风险提示类型（用于覆盖率）
    * `compliance_label_gt`：compliant / minor_violation / severe_violation（用于合规率）
    * `explainability_rubric_gt`：解释度维度的期望要素（用于解释度评分可对齐）

**(4) “触发点清单”（关键，用于指标1与3）**

* `events[]`：把对话中必须出现的关键事实/偏好变化列出来
  例：第3轮用户透露“可接受最大回撤 10%”、第5轮主题漂移到宏观、第7轮回到基金选择并应引用“最大回撤 10%”。

---

## 4) A 类（模拟多轮对话集）如何构造：能评 1-5 的“详细流程”

### 4.1 先做“场景脚本库”（不是直接生成对话）

你需要一份 **scenario blueprint**（建议 200–500 个），每个脚本包含：

1. `profile_gt`（上面那套真值画像）
2. `turn_plan`（每轮用户要透露/询问什么）
3. `events[]`（强制触发的记忆点、漂移点、合规诱导点）
4. `risk_required_map`（哪些轮必须触发哪些风险模板）
5. `forbidden_list`（这段对话中 assistant 严禁出现的语句类型：收益承诺/明确买卖/确定性预测等）

这样你才能在生成后自动验收“是否满足评测需要”。

---

### 4.2 用 LLM 生成“用户-助手双角色对话”，但用**硬约束提示词**

建议两段式生成（更稳）：

**步骤1：生成用户对话（只生成 user 轮）**
输入：profile_gt + turn_plan + events
输出：`user_turns[]`
约束：必须在指定轮次透露指定信息（风险偏好/期限/约束）。

**步骤2：生成助手对话（逐轮生成 assistant 轮）**
每一轮输入：

* 当前 user_turn
* 历史对话
* `profile_gt`（作为“隐藏真值”，用于生成正确的个性化解释）
* `risk_disclosure_required_gt`（本轮需要的提示类型）
* 合规规则（禁止清单）
  输出：
* assistant_text
* 并让模型同时输出结构化字段：`memory_required_keys_gt`、`compliance_label_gt`（通常应为 compliant）、`explainability_rubric_gt`（期望包含的解释要素）

> 这样你就能直接拿到 6.2(1-5) 的“真值标签”，后续跑你系统输出时做对比即可。

---

### 4.3 自动质检与再生成（必须做，否则合成集会“看起来对但无法评测”）

对每条对话跑一套 rule-based validator：

* **轮次结构检查**：是否达到 6–12 轮；是否包含“漂移→回收”至少一次（hard 集必须有）
* **画像真值注入检查**：用户是否在指定轮明确表达 risk_level/horizon/constraints
* **记忆点检查**：events[] 中的关键点是否真实出现且可抽取
* **风险提示检查**：要求出现的提示类型是否在 assistant 文本中出现（可用关键词/模板 ID 检测）
* **合规检查**：是否出现“买/卖指令、收益承诺、确定性预测”等（正则+关键词+LLM 判别双保险）

不通过就：**针对失败项局部重写**（不要整段重生成，成本高且引入新噪声）。

---

## 5) B 类（半真实交互集）怎么做，才能仍然评测 1-5？

B 的问题是：真人自由发挥会导致“真值画像不清晰、风险提示需求不明确”。解决办法是：**用“受控自由”**。

### 5.1 给测试者的“角色卡 + 任务卡”

每次交互给用户一张卡：

* 画像：风险等级/期限/约束（就是 profile_gt）
* 目标：比如“在不直接问买卖指令的情况下，逐步逼近一个选择”
* 必须在某些轮透露某些信息（比如第2轮提资金期限、第4轮提最大回撤底线）
* 可选自由发挥区：允许用户用自己的表述方式提问

这样 B 也能带真值画像与触发点。

### 5.2 B 的标注方式（建议“轻标注”）

* 画像真值：来自角色卡（无需事后猜）
* 风险提示需求：来自任务卡的 risk_required_map
* 合规标签：系统输出自动判别 + 人工抽检
* 解释度：人工 rubric 打分（3–5 人打分，取均值）

---

## 6) 指标 1-5：如何从数据集结构“直接计算”

这里给你“数据集→评测”的一一对应（确保可写进论文 + 可实现）：

### 指标1：上下文关联度 / 连续性

数据集中要有：`memory_required_keys_gt`（每个 assistant 轮应该引用的历史要点）

* 自动评测：你的系统输出里抽取是否提及这些 keys（关键词/embedding 匹配）
* 一致性：检查是否违背 `constraints_gt`（矛盾率）

### 指标2：画像提取准确率

数据集中要有：`profile_gt`

* 你的系统输出的画像（或记忆库中的画像条目）与 `profile_gt` 比对
* risk_level/horizon/liquidity 等字段做 Accuracy/F1

### 指标3：风险提示覆盖率

数据集中要有：`risk_disclosure_required_gt`

* 你的系统输出里是否触发对应提示类型（模板 ID 或文本匹配）
* Coverage = 满足提示要求的轮数 / 需要提示的轮数

### 指标4：内容合规率

数据集中要有：`forbidden_list` + `compliance_label_gt`

* 自动检测你系统输出是否触犯禁区
* 报告 compliant/minor/severe 的比例（严重违规单列）

### 指标5：决策辅助解释度

数据集中要有：`explainability_rubric_gt`（期望要素，如：比较维度/风险收益/与画像匹配/不越界建议）

* 自动：检查结构要素是否出现（分点、对比维度、风险提示等）
* 人工：rubric 1–5 分（信息依据、逻辑结构、画像匹配、可操作但不越界）

---

## 7) 推荐的数据规模（够写论文也不至于爆炸）

* **A（模拟）**：600–2000 段对话（每段 6–12 轮）

  * easy:med:hard = 3:4:3
  * 合规对抗子集单独 100–300 段
* **B（半真实）**：50–150 段对话（更贵，用于“真实交互有效性”章节支撑）

---

## 8) 你可以直接复用/借鉴的公开数据（当“种子”而非终点）

* **ConvFinQA**：学“多轮引用/省略/回指 + 数值链式追问”的结构设计。([finllm-leaderboard.readthedocs.io][1])
* **FinTalk-19k**：学真实用户语气与问题类型覆盖（个人理财/情绪/困惑表达）。([Hugging Face][2])
* **DISC-Fin-SFT**：学中文金融问答表达与咨询语气（但要你自己做多轮与真值标注）。([GitHub][3])

