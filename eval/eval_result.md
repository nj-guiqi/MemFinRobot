
## 实验结果汇总

MemFinRobot:/Users/nijian.15/projects/MemFinRobot/eval/runs/20260224_085203/report.md

mem0:/Users/nijian.15/projects/MemFinRobot/eval/runs/20260220_155804/report_mem0.md

LLM:/Users/nijian.15/projects/MemFinRobot/eval/runs/20260221_085707/report_llm.md

FinRobot:/Users/nijian.15/projects/MemFinRobot/eval/runs/20260222_055021/report_finrobot.md

LangMem:/Users/nijian.15/projects/MemFinRobot/eval/runs/20260222_072551/report_langmem.md

## 汇总结果

注：带 `↓` 表示越低越好；`LLM` 的 `m1_*` 因 `eligible_count=0` 记为 `-`；`mem0/LLM/FinRobot/LangMem` 的 `m4_*` 已用 `ComplianceGuard` 基于 `pred_assistant_text` 重新计算（替代适配器硬编码合规）。

| Method | run_id | m1_key_cov | m1_strict_hit | m1_contra↓ | m1_short_hit | m1_long_hit | m1_profile_hit | m2_profile_score | m3_risk_cov | m3_strict_risk | m4_acc | m4_severe↓ | m5_rubric_hit | m5_judge_mean |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| MemFinRobot | 20260224_085203 | 0.3070 | 0.1287 | 0.5017 | 0.2957 | 0.0664 | 0.0038 | 0.2281 | 0.8361 | 0.6656 | 0.5458 | 0.4024 | 0.9582 | 4.8371 |
| mem0 | 20260220_155804 | 0.3440 | 0.1520 | 0.6858 | 0.3427 | 0.0539 | 0.0000 | 0.1716 | 0.5412 | 0.1495 | 0.3204 | 0.6634 | 0.9085 | 4.6372 |
| LLM | 20260221_085707 | - | - | - | - | - | - | 0.1625 | 0.5361 | 0.1494 | 0.5380 | 0.4241 | 0.8704 | 4.4683 |
| FinRobot | 20260222_055021 | 0.3622 | 0.1518 | 0.6238 | 0.3622 | 0.0000 | 0.0000 | 0.1679 | 0.5097 | 0.1494 | 0.5443 | 0.4525 | 0.8934 | 4.5462 |
| LangMem | 20260222_072551 | 0.3697 | 0.1551 | 0.7525 | 0.3672 | 0.0539 | 0.0000 | 0.1865 | 0.4500 | 0.1364 | 0.4652 | 0.5285 | 0.8593 | 4.4102 |

## 指标分析

M1（上下文连续性）上，本方法在长期信息复用与约束一致性两方面呈现出更符合金融交付要求的特征。首先，MemFinRobot 的 `m1_long_hit=0.0664` ，均高于两个带有记忆的对话系统， mem0 与 LangMem（均为 `0.0539`），标明本方法中长期记忆的建模方式相对已有的先进方法能更有效召回目标记忆。其次，在更关键的“一致性”维度上，MemFinRobot 的 `m1_contra↓=0.5017` 在可评估方法中最低，显著优于 mem0（`0.6858`）、FinRobot（`0.6238`）与 LangMem（`0.7525`）。这说明，本方法除了追求更强的跨轮引用，同时也将“约束不冲突”作为生成与审校的重点目标，从而在多轮金融对话中更稳定地避免硬约束违背与语义自相矛盾。
M2 指标显示LangMem 为 0.1865、MemFinRobot 为 0.1853、mem0 为 0.1716、FinRobot 为 0.1679、纯 LLM 为 0.1625。该结果表明，结果显示带有记忆能力的方法高于不带记忆的方法，说明了记忆能力带来更强的用户画像对齐能力，而更强的画像一致性能作用于前后对话的一致性。MemFinRobot 在该指标上达到最优并显著高于其他方法。这主要得益于其显式画像维护与记忆管理设计，使用户画像内容能够跨轮更新、持久化并以结构化方式参与后续决策，从而降低跨轮漂移与遗忘带来的对齐误差。相对地，纯大语言模型缺少跨轮状态，画像只能依赖即时文本线索被动推断；FinRobot 侧重工具与流程编排，画像并非核心建模对象；mem0/LangMem 的“检索-拼接”式记忆注入若缺少稳定的画像抽取与更新，容易引入召回噪声或造成字段不一致。值得注意的是，LangMem 在 M2 上略高于本方法，说明在当前口径与样本规模下二者差距处于很小量级；但本方法的优势在于其画像状态可与合规约束与解释生成联动，从而在更关键的安全与可解释交付目标上形成一致性提升（见M4,M5指标）。
M3（风险提示覆盖）上，MemFinRobot 在覆盖与严格覆盖两项均显著占优：`m3_risk_cov=0.8361`、`m3_strict_risk=0.6656`，远高于 mem0（`0.5412/0.1495`）、LLM（`0.5361/0.1494`）、FinRobot（`0.5097/0.1494`）与 LangMem（`0.4500/0.1364`）。该结果说明，本方法能够更稳定地命中“应披露风险清单”，并减少风险要素缺项。结合系统实现可见，模型输出在合规审校前引入了风险表达补足机制（对缺失风险类别进行结构化补齐），从机制上抬升了风险要素覆盖的下限；同时，风险披露被纳入整体工作流约束，而非依赖模型的自由发挥，因此在严格覆盖率上体现出显著优势。这一特征直接契合金融场景对“风险提示完整性”的硬性要求，也为后续合规与可解释交付提供了稳定的内容基座。
M4 上本方法明确领先：合规标签准确度为0.5458 ，违规标签率为0.4024 ，达到所有方法中的最优。FinRobot 与 LLM 的 合规标签准确度接近（0.5443 vs 0.5380），但违规标签率分别为 0.4525 与 0.4241；LangMem 的 m4_acc 为 0.4652 且 m4_severe 为 0.5285；mem0 风险最突出（m4_acc=0.3204, m4_severe=0.6634）。该结果直接表明：金融对话的安全与合规需要在系统层显式建模与约束，单纯引入记忆或工具并不足以保证底线风险可控。MemFinRobot 在生成阶段引入合规防护与风险表达约束，能够主动抑制禁区措辞与高风险承诺式表达，从而显著降低严重违规；而 mem0/LangMem 的召回注入若缺少“合规优先”的过滤与重写，可能将历史片段中的高风险措辞带入当前回复并放大触发概率；FinRobot/LLM 缺少专门的红线抑制与审校环节，因此在严重违规率上难以达到 MemFinRobot 的水平。因此，m4_acc 与 m4_severe 的“同时占优”更能体现 MemFinRobot 的方法优势：不仅与标注的合规等级更一致，而且在最关键的底线风险事件上具备更低的触发频率，符合金融场景对安全交付的核心要求。
M5 上 MemFinRobot 同样排名第一，可解释度为0.9209、规范后得分4.6769；显著优于 mem0（0.9085, 4.6372）、FinRobot（0.8934, 4.5462）、LLM（0.8704, 4.4683）、LangMem（0.8593, 4.4102）。MemFinRobot 的领先与其系统设计一致：工具链输出的证据与中间结果为解释提供了可引用的信息载体，工作流约束使得这些信息更容易被组织为结构化论证，从而提升可解释度。相对地，大语言模型的解释更依赖通用话术，易出现要素缺失；mem0/LangMem 的检索式注入并不等同于解释结构，召回噪声可能占据篇幅并导致覆盖不稳定；FinRobot 侧重流程完成，对解释要素覆盖缺少显式驱动，因此整体落后于 MemFinRobot。综合而言，MemFinRobot 在 M5 的领先意味着其更接近金融咨询的可交付形态：解释要素齐备且可审计。并且与 M4 的显著优势共同说明本文方法不仅“能给建议”，更能在安全约束下给出结构化、可解释的决策支持输出。


## 分层对比

### M1_long_hit 分层分析（对比 mem0 与 LangMem）

为保证统计口径严格一致，本节按各方法在对应层级内的 `long_term_hit_total / required_key_total` 计算 `m1_long_hit`，并显式报告分子与分母，避免由于 `eligible_m1` 差异导致的解释偏差。

#### 按 `scenario_type` 分层

| scenario_type | MemFinRobot | mem0 | LangMem |
| --- | --- | --- | --- |
| 产品比较 | 11/141 (0.0780) | 7/141 (0.0496) | 15/141 (0.1064) |
| 宏观分析 | 4/111 (0.0360) | 3/107 (0.0280) | 7/111 (0.0631) |
| 投资教育 | 7/174 (0.0402) | 19/174 (0.1092) | 10/174 (0.0575) |
| 行业分析 | 16/132 (0.1212) | 7/127 (0.0551) | 6/132 (0.0455) |
| 行情解读 | 1/28 (0.0357) | 1/28 (0.0357) | 0/28 (0.0000) |
| 财务分析 | 6/84 (0.0714) | 1/74 (0.0135) | 2/84 (0.0238) |
| 风险识别 | 8/128 (0.0625) | 4/128 (0.0313) | 3/128 (0.0234) |

从场景异质性看，MemFinRobot 在 `行业分析`、`财务分析` 与 `风险识别` 三类场景取得最优，且在后两类中相对 mem0/LangMem 的优势为倍数级（例如 `财务分析`：0.0714 vs 0.0135/0.0238）。这表明当任务需要跨轮整合结构化事实与约束条件时，本方法对长期记忆的“可用性”更高。另一方面，在 `产品比较` 与 `宏观分析` 场景下，LangMem 的 `m1_long_hit` 更高，提示检索式记忆在特定开放场景中仍具局部优势；`投资教育` 场景则由 mem0 领先，说明该场景对长期记忆触发模式与表达策略更敏感，尚存在进一步优化空间。

#### 按 `difficulty` 分层

| difficulty | MemFinRobot | mem0 | LangMem | FinRobot | LLM |
| --- | --- | --- | --- | --- | --- |
| easy | 23/358 (0.0642) | 14/353 (0.0397) | 17/358 (0.0475) | 0/358 (0.0000) | - |
| medium | 9/121 (0.0744) | 8/121 (0.0661) | 4/121 (0.0331) | 0/121 (0.0000) | - |
| hard | 21/305 (0.0689) | 20/291 (0.0687) | 22/305 (0.0721) | 0/305 (0.0000) | - |
| med | 0/14 (0.0000) | 0/14 (0.0000) | 0/14 (0.0000) | 0/14 (0.0000) | - |

在难度维度上，MemFinRobot 在 `easy` 与 `medium` 两档均为最优，并在这两档显著优于 FinRobot（均为 0.0000）；在 `hard` 档与 LangMem/mem0 接近（0.0689 vs 0.0721/0.0687），但仍保持对 FinRobot 的稳定优势。该结果说明，本方法对长期记忆的利用优势并非局限于低难样本，而是能够在中等难度任务中继续保持较高命中。另一方面，FinRobot 在各难度层均未形成长期记忆命中（`m1_long_hit=0`），提示其跨轮信息复用主要依赖短期上下文或流程状态而非长期记忆通道。`LLM` 在 M1 下 `eligible_count=0`，因此其难度分层 `m1_long_hit` 不可评估（记为 `-`）。此外，数据中同时存在 `medium` 与 `med` 两个标签，其中 `med` 分母仅 14 且各可评估方法均为 0，故不宜据此做强结论。

### M5_judge_mean 分层分析（包含全部方法）

本节按各层级内 `judge_score_1_5` 的算术平均计算 `m5_judge_mean`，并在单元格中显式标注样本量 `n`。需注意，不同方法在少数场景上的 `n` 存在轻微差异（由 `eligible_m5` 与轮状态共同决定），因此解释时应同时参考均值与样本量。

#### 按 `scenario_type` 分层

| scenario_type | MemFinRobot | mem0 | LLM | FinRobot | LangMem |
| --- | --- | --- | --- | --- | --- |
| 产品比较 | 4.7722 (n=60) | 4.6557 (n=60) | 4.3925 (n=60) | 4.5945 (n=60) | 4.5390 (n=60) |
| 宏观分析 | 4.9552 (n=52) | 4.8498 (n=51) | 4.5258 (n=52) | 4.8208 (n=52) | 4.2377 (n=52) |
| 投资教育 | 4.8132 (n=66) | 4.5233 (n=66) | 4.4102 (n=66) | 4.5841 (n=66) | 4.3618 (n=66) |
| 行业分析 | 4.9556 (n=45) | 4.8528 (n=43) | 4.5336 (n=45) | 4.4596 (n=45) | 4.4816 (n=45) |
| 行情解读 | 4.9231 (n=13) | 4.5131 (n=13) | 4.4615 (n=13) | 4.6415 (n=13) | 4.8977 (n=13) |
| 财务分析 | 4.6870 (n=33) | 4.6000 (n=30) | 4.6471 (n=34) | 4.2747 (n=34) | 4.4709 (n=34) |
| 风险识别 | 4.7900 (n=46) | 4.3987 (n=46) | 4.3917 (n=46) | 4.3772 (n=46) | 4.2543 (n=46) |

在 `scenario_type` 维度上，MemFinRobot 在七个场景中均取得最高 `m5_judge_mean`，显示其解释质量优势具有跨场景稳定性，而非依赖单一任务类型。优势最显著的场景集中在 `宏观分析`、`行业分析` 与 `风险识别`，这与系统在“证据组织 + 风险边界表达”上的联合约束机制一致；相对地，LLM/FinRobot/LangMem 在上述高复杂度场景的均值明显回落，说明仅靠通用生成或流程编排难以稳定覆盖高质量解释所需要素。

#### 按 `difficulty` 分层

| difficulty | MemFinRobot | mem0 | LLM | FinRobot | LangMem |
| --- | --- | --- | --- | --- | --- |
| easy | 4.8085 (n=134) | 4.5572 (n=132) | 4.4708 (n=134) | 4.4579 (n=134) | 4.3312 (n=134) |
| medium | 4.7223 (n=48) | 4.4446 (n=48) | 4.1808 (n=48) | 4.6671 (n=48) | 4.2227 (n=48) |
| hard | 4.9134 (n=127) | 4.7788 (n=122) | 4.5608 (n=127) | 4.6186 (n=127) | 4.5398 (n=127) |
| med | 4.7783 (n=6) | 5.0000 (n=7) | 4.7143 (n=7) | 4.0957 (n=7) | 4.8571 (n=7) |

在 `difficulty` 维度上，MemFinRobot 在 `easy`、`medium` 与 `hard` 三个主要难度档均保持第一，说明其解释质量优势在任务难度提升后未发生系统性退化。`hard` 档中本方法仍达到 4.9134，且较次优方法保持稳定差距，表明在高难样本上仍能维持较高的解释完备性与一致性。`med` 标签样本量极小（各方法 `n≈6-7`），其波动更可能反映抽样噪声而非稳态性能差异，因此不应作为主结论依据。
