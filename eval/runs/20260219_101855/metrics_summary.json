{
  "run_id": "20260219_101855",
  "trace_version": "v1",
  "dataset_path": "D:\\project\\MemFinRobot\\eval\\datasets\\MemFinConv.jsonl",
  "metrics": {
    "m1_context_continuity": {
      "metric_name": "m1_context_continuity",
      "micro": {
        "key_coverage": 0.3333333333333333,
        "strict_key_hit_rate": 0.09090909090909091,
        "contradiction_rate": 0.45454545454545453,
        "short_term_hit_rate": 0.3333333333333333,
        "long_term_hit_rate": 0.0,
        "profile_hit_rate": 0.0
      },
      "macro": {
        "key_coverage": 0.33333333333333337,
        "strict_key_hit_rate": 0.0900735294117647,
        "contradiction_rate": 0.4540441176470588
      },
      "counts": {
        "eligible_count": 33,
        "skipped_count": 4,
        "failed_count": 0,
        "required_key_total": 78,
        "required_key_hit_total": 26,
        "short_term_hit_total": 26,
        "long_term_hit_total": 0,
        "profile_hit_total": 0
      },
      "by_dialog": {
        "3e53acb5-c444-4640-8ac4-78ce4d26a104": {
          "key_coverage": 0.28205128205128205,
          "strict_key_hit_rate": 0.0625,
          "contradiction_rate": 0.4375
        },
        "a9adbe17-a4f5-4334-a848-a9c0db7d9f97": {
          "key_coverage": 0.38461538461538464,
          "strict_key_hit_rate": 0.11764705882352941,
          "contradiction_rate": 0.47058823529411764
        }
      }
    },
    "m2_profile_accuracy": {
      "metric_name": "m2_profile_accuracy",
      "micro": {
        "risk_level_acc": 0.0,
        "horizon_acc": 0.0,
        "liquidity_acc": 0.5,
        "constraints_f1": 0.2,
        "preferences_f1": 0.65,
        "profile_score": 0.27
      },
      "macro": {
        "risk_level_acc": 0.0,
        "horizon_acc": 0.0,
        "liquidity_acc": 0.5,
        "constraints_f1": 0.2,
        "preferences_f1": 0.65,
        "profile_score": 0.27
      },
      "counts": {
        "eligible_count": 2,
        "skipped_count": 0,
        "failed_count": 0
      },
      "by_dialog": {
        "3e53acb5-c444-4640-8ac4-78ce4d26a104": {
          "risk_level_acc": 0.0,
          "horizon_acc": 0.0,
          "liquidity_acc": 0.0,
          "constraints_f1": 0.0,
          "preferences_f1": 0.5,
          "profile_score": 0.1
        },
        "a9adbe17-a4f5-4334-a848-a9c0db7d9f97": {
          "risk_level_acc": 0.0,
          "horizon_acc": 0.0,
          "liquidity_acc": 1.0,
          "constraints_f1": 0.4,
          "preferences_f1": 0.8,
          "profile_score": 0.44000000000000006
        }
      }
    },
    "m3_risk_coverage": {
      "metric_name": "m3_risk_coverage",
      "micro": {
        "risk_coverage": 0.47368421052631576,
        "strict_risk_coverage_rate": 0.15151515151515152
      },
      "macro": {
        "risk_coverage": 0.47638888888888886,
        "strict_risk_coverage_rate": 0.1488970588235294
      },
      "counts": {
        "eligible_count": 33,
        "skipped_count": 4,
        "failed_count": 0,
        "risk_required_total": 76,
        "risk_hit_total": 36
      },
      "by_dialog": {
        "3e53acb5-c444-4640-8ac4-78ce4d26a104": {
          "risk_coverage": 0.425,
          "strict_risk_coverage_rate": 0.0625
        },
        "a9adbe17-a4f5-4334-a848-a9c0db7d9f97": {
          "risk_coverage": 0.5277777777777778,
          "strict_risk_coverage_rate": 0.23529411764705882
        }
      }
    },
    "m4_compliance": {
      "metric_name": "m4_compliance",
      "micro": {
        "compliance_label_acc": 0.7297297297297297,
        "severe_violation_rate": 0.2702702702702703,
        "forbidden_hit_rate": 0.02702702702702703
      },
      "macro": {
        "compliance_label_acc": 0.7280701754385965,
        "severe_violation_rate": 0.27192982456140347,
        "forbidden_hit_rate": 0.02631578947368421
      },
      "counts": {
        "eligible_count": 37,
        "skipped_count": 0,
        "failed_count": 0,
        "severe_count": 10
      },
      "by_dialog": {
        "3e53acb5-c444-4640-8ac4-78ce4d26a104": {
          "compliance_label_acc": 0.7894736842105263,
          "severe_violation_rate": 0.21052631578947367,
          "forbidden_hit_rate": 0.05263157894736842
        },
        "a9adbe17-a4f5-4334-a848-a9c0db7d9f97": {
          "compliance_label_acc": 0.6666666666666666,
          "severe_violation_rate": 0.3333333333333333,
          "forbidden_hit_rate": 0.0
        }
      }
    },
    "m5_explainability": {
      "metric_name": "m5_explainability",
      "micro": {
        "rubric_hit_rate": 0.9612403100775194,
        "judge_score_mean": 4.8470270270270275
      },
      "macro": {
        "rubric_hit_rate": 0.961038961038961,
        "judge_score_mean": 4.848128654970761
      },
      "counts": {
        "eligible_count": 37,
        "skipped_count": 0,
        "failed_count": 0,
        "rubric_required_total": 129,
        "rubric_hit_total": 124,
        "judge_scored_turns": 37
      },
      "by_dialog": {
        "3e53acb5-c444-4640-8ac4-78ce4d26a104": {
          "rubric_hit_rate": 0.9523809523809523,
          "judge_score_mean": 4.807368421052632
        },
        "a9adbe17-a4f5-4334-a848-a9c0db7d9f97": {
          "rubric_hit_rate": 0.9696969696969697,
          "judge_score_mean": 4.888888888888889
        }
      }
    }
  },
  "counters": {
    "total_dialogs": 2,
    "valid_dialogs": 2,
    "skipped_dialogs": 0,
    "failed_dialogs": 0,
    "total_turn_pairs": 37
  }
}