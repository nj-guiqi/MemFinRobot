## 2.1 多轮对话智能体的发展与局限

### 2.1.1 大语言模型在多轮对话中的能力边界

* 上下文窗口限制
* 长对话退化问题
* 长期一致性问题
* 幻觉与遗忘问题

👉 目标：说明目前LLM在长上下文下能力衰弱，证明 LLM 自身不具备长期认知能力

---

### 2.1.2 智能体架构的发展

* ReAct
* Toolformer
* Planner-Executor
* 多模块Agent

👉 强调：智能体的发展，扩展LLM的能力，但它们解决的是“工具调用问题”，不是“长期认知问题”

---

## 2.2 长期记忆机制研究现状

### 2.2.1 记忆的理论来源（认知科学 + AI）

* 工作记忆 vs 长期记忆
* episodic memory
* semantic memory
* cognitive state

👉 给你第3章打理论基础

---

### 2.2.2 现有记忆的研究

我上传的memory的综述，将记忆的研究分类阐述

👉 评述它们的缺陷：

* 只做“召回相似文本”
* 没做“状态建模”
* 没有一致性控制

---

### 可选：2.2.3 长期一致性问题的研究

* Consistency in dialogue
* Persona consistency
* Temporal consistency
* Narrative consistency

👉 引出你“决策一致性”概念。如果没有相关的文献，就把这部分表述合并到2.2.2.去掉该点

---

## 2.3 金融场景下的智能投顾与Agent研究

### 2.3.1 传统智能投顾

* 规则引擎
* 马科维茨模型
* 强化学习配置

强调：需要你找到若干有联系的文献或者业界开源、闭源工作，并引用

---

### 2.3.2 金融大模型

* FinGPT
* BloombergGPT
* FinRobot
* 金融RAG系统

强调：需要你找到若干有联系的文献或者业界开源、闭源工作，并引用

---

### 可选：2.3.3 金融场景的特殊性 

* 高合规要求
* 风险披露必须一致
* 用户画像不可漂移
* 不能前后给不同立场

强调：需要你总结现有研究、开源、闭源工作在满足经济金融场景特殊性所做的工作

